<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><script src="/blogs/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blogs/livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>PRML-DL | LArielO&#39;s LAB</title>
<meta name="keywords" content="">
<meta name="description" content="Batch Norm
Reference：
https://www.zhihu.com/question/553541499/answer/1892702115723452465
https://zhuanlan.zhihu.com/p/54530247
ICS
内部协变量偏移（Internal Covariate Shift, ICS）指神经网络在训练过程中，由于前一层的参数更新导致后续层的输入分布发生显著变化的现象。这种分布的不稳定性会降低训练效率，增加模型收敛的难度。这种现象在深层网络中尤为明显， 是导致训练不稳定、收敛缓慢甚至梯度消失/爆炸的原因之一。
   ICS发生的主要原因：

    1）网络参数更新导致分布变化；

    2) 非线性激活函数的敏感性问题；[ReLU](https://zhida.zhihu.com/search?content_id=721744268&amp;content_type=Answer&amp;match_order=1&amp;q=ReLU&amp;zhida_source=entity)、[Sigmoid](https://zhida.zhihu.com/search?content_id=721744268&amp;content_type=Answer&amp;match_order=1&amp;q=Sigmoid&amp;zhida_source=entity)、[Tanh](https://zhida.zhihu.com/search?content_id=721744268&amp;content_type=Answer&amp;match_order=1&amp;q=Tanh&amp;zhida_source=entity)等非线性激活函数对不同输入范围的响应不同，如果前一层的输出分布偏移到激活函数的饱和区（如Sigmoid的两端), 梯度会变得极小(梯度消失),  导致训练停滞。

    3）深度网络的累积效应； 即使每一层变化很小，由于多层叠加后， 输入分布的偏移会被放大，导致深层网络的输入分布剧烈波动；

    4）梯度下降的依赖问题； 梯度下降算法假设输入数据的分布是稳定的， 但内部协变量偏移打破了这一假设， 使得优化过程变得不稳定。 由于每一层的输入分布不断变化，优化器需要不断调整学习率， 导致训练收敛变慢。

Batch Normalization（BN）通过对每一层的输入进行标准化（Normalization），使得数据分布更加稳定，是解决『内部协变量偏移』的一种有效方式。
BN limitation

LN：Layer Norm

# NLP Example
batch, sentence_length, embedding_dim = 20, 5, 10
embedding = torch.randn(batch, sentence_length, embedding_dim)
# 指定归一化的维度
layer_norm = nn.LayerNorm(embedding_dim)
# 进行归一化
layer_norm(embedding)
 
# Image Example
N, C, H, W = 20, 5, 10, 10
input = torch.randn(N, C, H, W)
# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)
# as shown in the image below
layer_norm = nn.LayerNorm([C, H, W])
output = layer_norm(input)
RMSNorm应该是LayerNorm砍掉算均值这一步，不强求中心一致。faster">
<meta name="author" content="LArielO">
<link rel="canonical" href="http://localhost:1313/blogs/posts/prml-dl/">
<link crossorigin="anonymous" href="/blogs/assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/blogs/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/blogs/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/blogs/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/blogs/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/blogs/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/blogs/posts/prml-dl/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@400;600&family=Noto+Serif+SC:wght@400;600&family=IBM+Plex+Mono:wght@400;500;600&display=swap" rel="stylesheet">


<link rel="icon" type="image/x-icon" href="/blogs/favicon.ico">
<link rel="apple-touch-icon" sizes="180x180" href="/blogs/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/blogs/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/blogs/favicon-16x16.png">
<link rel="manifest" href="/blogs/site.webmanifest">


<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script','noscript','style','textarea','pre','code'],
      ignoreHtmlClass: 'tex2jax_ignore',
      processHtmlClass: 'tex2jax_process'
    },
    svg: { fontCache: 'global' }   
  };
</script>


<script defer src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>


</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/blogs/" accesskey="h" title="LArielO&#39;s LAB (Alt + H)">
                <img src="http://localhost:1313/blogs/android-chrome-512x512.png" alt="" aria-label="logo"
                    height="28">LArielO&#39;s LAB</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/blogs/" title="Main">
                    <span>Main</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blogs/archive/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blogs/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blogs/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/blogs/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/blogs/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      PRML-DL
    </h1>
    <div class="post-meta"><span title='2025-11-03 11:04:46 +0000 UTC'>November 3, 2025</span>&nbsp;·&nbsp;<span>8 min</span>&nbsp;·&nbsp;<span>1536 words</span>&nbsp;·&nbsp;<span>LArielO</span>

</div>
  </header> 
  <div class="post-content"><h2 id="batch-norm">Batch Norm<a hidden class="anchor" aria-hidden="true" href="#batch-norm">#</a></h2>
<p>Reference：</p>
<p><a href="https://www.zhihu.com/question/553541499/answer/1892702115723452465">https://www.zhihu.com/question/553541499/answer/1892702115723452465</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/54530247">https://zhuanlan.zhihu.com/p/54530247</a></p>
<h3 id="ics">ICS<a hidden class="anchor" aria-hidden="true" href="#ics">#</a></h3>
<p>内部协变量偏移（Internal Covariate Shift, ICS）指神经网络在训练过程中，由于前一层的参数更新导致后续层的输入分布发生显著变化的现象。这种分布的不稳定性会降低训练效率，增加模型收敛的难度。这种现象在深层网络中尤为明显， 是导致训练不稳定、收敛缓慢甚至<a href="https://zhida.zhihu.com/search?content_id=721744268&amp;content_type=Answer&amp;match_order=1&amp;q=%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1&amp;zhida_source=entity">梯度消失</a>/爆炸的原因之一。</p>
<pre><code>   ICS发生的主要原因：

    1）网络参数更新导致分布变化；

    2) 非线性激活函数的敏感性问题；[ReLU](https://zhida.zhihu.com/search?content_id=721744268&amp;content_type=Answer&amp;match_order=1&amp;q=ReLU&amp;zhida_source=entity)、[Sigmoid](https://zhida.zhihu.com/search?content_id=721744268&amp;content_type=Answer&amp;match_order=1&amp;q=Sigmoid&amp;zhida_source=entity)、[Tanh](https://zhida.zhihu.com/search?content_id=721744268&amp;content_type=Answer&amp;match_order=1&amp;q=Tanh&amp;zhida_source=entity)等非线性激活函数对不同输入范围的响应不同，如果前一层的输出分布偏移到激活函数的饱和区（如Sigmoid的两端), 梯度会变得极小(梯度消失),  导致训练停滞。

    3）深度网络的累积效应； 即使每一层变化很小，由于多层叠加后， 输入分布的偏移会被放大，导致深层网络的输入分布剧烈波动；

    4）梯度下降的依赖问题； 梯度下降算法假设输入数据的分布是稳定的， 但内部协变量偏移打破了这一假设， 使得优化过程变得不稳定。 由于每一层的输入分布不断变化，优化器需要不断调整学习率， 导致训练收敛变慢。
</code></pre>
<p>Batch Normalization（BN）通过对每一层的输入进行标准化（Normalization），使得数据分布更加稳定，是解决『内部协变量偏移』的一种有效方式。</p>
<h3 id="bn-limitation">BN limitation<a hidden class="anchor" aria-hidden="true" href="#bn-limitation">#</a></h3>
<p><img alt="image" loading="lazy" src="/blogs/images/HwFPbofd6og0O6xuDjlcoeJhnEc.png"></p>
<h3 id="lnlayer-norm">LN：Layer Norm<a hidden class="anchor" aria-hidden="true" href="#lnlayer-norm">#</a></h3>
<p><img alt="image" loading="lazy" src="/blogs/images/WoqIbAeSFocPP6xvN19cda14nfc.png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># NLP Example</span>
</span></span><span style="display:flex;"><span>batch, sentence_length, embedding_dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(batch, sentence_length, embedding_dim)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 指定归一化的维度</span>
</span></span><span style="display:flex;"><span>layer_norm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LayerNorm(embedding_dim)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 进行归一化</span>
</span></span><span style="display:flex;"><span>layer_norm(embedding)
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Image Example</span>
</span></span><span style="display:flex;"><span>N, C, H, W <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(N, C, H, W)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Normalize over the last three dimensions (i.e. the channel and spatial dimensions)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># as shown in the image below</span>
</span></span><span style="display:flex;"><span>layer_norm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LayerNorm([C, H, W])
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> layer_norm(input)
</span></span></code></pre></div><p>RMSNorm应该是LayerNorm砍掉算均值这一步，不强求中心一致。faster</p>
<h4 id="稳定训练防止梯度爆炸消失">稳定训练，防止梯度爆炸/消失<a hidden class="anchor" aria-hidden="true" href="#稳定训练防止梯度爆炸消失">#</a></h4>
<ul>
<li>
<p>深层网络中每一层输出的尺度会不断变化，容易导致：</p>
<ul>
<li>梯度爆炸（数值变得特别大）
<ul>
<li>梯度消失（数值趋近于0）</li>
</ul>
</li>
</ul>
</li>
<li>
<p>RMSNorm 通过统一每个 token 向量的“长度”，让每层的输出保持在稳定范围内。</p>
</li>
</ul>
<p>类比：像做体操前“先把身体拉开”，让后续动作更安全、流畅。</p>
<hr>
<h4 id="加快收敛提升训练速度">加快收敛，提升训练速度<a hidden class="anchor" aria-hidden="true" href="#加快收敛提升训练速度">#</a></h4>
<ul>
<li>
<p>归一化后每层的输入分布更“标准”，优化器收敛更快；</p>
</li>
<li>
<p>在不需要预热很长时间的情况下就能达到稳定训练效果；</p>
</li>
<li>
<p>RMSNorm 的实现更简单，计算量小于 LayerNorm，对硬件友好。</p>
</li>
</ul>
<p>类比：就像跑步前热身，让你跑得更快、避免受伤。</p>
<hr>
<h4 id="提升模型泛化能力">提升模型泛化能力<a hidden class="anchor" aria-hidden="true" href="#提升模型泛化能力">#</a></h4>
<ul>
<li>
<p>归一化后，模型不会偏向某些维度/特征；</p>
</li>
<li>
<p>输出分布在各维度上更均匀，有助于模型在验证集、测试集上表现更好。</p>
</li>
</ul>
<hr>
<h2 id="positional-encoding">Positional Encoding<a hidden class="anchor" aria-hidden="true" href="#positional-encoding">#</a></h2>
<p>Reference：</p>
<p><a href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/427388113">https://zhuanlan.zhihu.com/p/427388113</a></p>
<p><a href="https://spaces.ac.cn/archives/10352">https://spaces.ac.cn/archives/10352</a></p>
<p>把一个词转换成向量，就好像把一个词映射到了一个高维空间的位置，意思相近的词会在高维空间内比较靠近，而加上位置向量，会让位置相近的词更靠近，位置远的词离得更远。为什么用cos，sin这种方式，使用sin和cos编码可以得到词语之间的相对位置。</p>
<h3 id="rope-rotary-position-embedding">RoPE (Rotary Position Embedding)<a hidden class="anchor" aria-hidden="true" href="#rope-rotary-position-embedding">#</a></h3>
<p><img alt="image" loading="lazy" src="/blogs/images/LHeYbyvZzoGNMXxvdnocjdFEn4L.png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 传统方法：位置信息加到向量上</span>
</span></span><span style="display:flex;"><span>x_with_pos <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> pos_embedding
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># RoPE：通过旋转变换编码位置</span>
</span></span><span style="display:flex;"><span>x_with_pos <span style="color:#f92672">=</span> rotate(x, position_angle)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 对于位置m的token，其query/key向量被旋转θ*m角度</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rope_rotation</span>(x, position, dim):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 计算旋转角度</span>
</span></span><span style="display:flex;"><span>    theta <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000</span> <span style="color:#f92672">**</span> (<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, dim, <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> dim)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 位置m的旋转角度</span>
</span></span><span style="display:flex;"><span>    angles <span style="color:#f92672">=</span> position <span style="color:#f92672">*</span> theta
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 构造旋转矩阵并应用</span>
</span></span><span style="display:flex;"><span>    cos_vals <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>cos(angles)
</span></span><span style="display:flex;"><span>    sin_vals <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sin(angles)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 旋转变换（简化版）</span>
</span></span><span style="display:flex;"><span>    x_rotated <span style="color:#f92672">=</span> apply_rotation(x, cos_vals, sin_vals)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x_rotated
</span></span></code></pre></div><h3 id="multi-modality-position多模态位置">multi-modality position多模态位置<a hidden class="anchor" aria-hidden="true" href="#multi-modality-position多模态位置">#</a></h3>
<h4 id="多模位置">多模位置<a hidden class="anchor" aria-hidden="true" href="#多模位置">#</a></h4>
<p>多模态模型居然连位置编码都没有形成共识。对于文本LLM，目前主流的位置编码是<a href="https://spaces.ac.cn/archives/8265">RoPE</a>（RoPE就不展开介绍了，假设读者已经熟知），更准确来说是RoPE-1D，因为原始设计只适用于1D序列。后来我们推导了<a href="https://spaces.ac.cn/archives/8397">RoPE-2D</a>，这可以用于图像等2D序列，按照RoPE-2D的思路我们可以平行地推广到RoPE-3D，用于视频等3D序列。</p>
<p>然而，以上说的只是单一模态输入，当多种模态混合输入时，困难就出现了：文本是1D序列，所以它的位置只是一个标量nn；图像是2D的（“宽”和“高”），所以表达它的位置需要一个二维向量(x,y)(x,y)；视频则在图像的基础上新增了一个时间维度（或者说“帧”），所以它的位置是一个三维向量(x,y,z)(x,y,z)。当我们希望用同一个模型去处理三种模态的数据时，就要想办法糅合这三种不同形式的位置信息。</p>
<p>RoPE在实现上是绝对位置编码，但结合基于内积的Attention来用时，内积之后位置会自动作差，（想象两个向量做内积只跟夹角有关，一个意思）从而实现了相对位置编码的效果。可同一大小的向量可以作差，不同大小的向量怎么作差呢？这就是多模态位置编码的困难所在。</p>
<p>不少工作选择“逃避”这个困难，直接Flatten所有模态然后使用RoPE-1D，这不失为一种解决办法，但终究显得不够优雅。此外，强行Flatten也可能会降低模型性能的天花板，因为<a href="https://papers.cool/arxiv/2403.00522">《VisionLLaMA: A Unified LLaMA Backbone for Vision Tasks》</a>等工作已经表明，RoPE-2D的引入有助于提升模型效果尤其是变分辨率输入的效果。</p>
<h2 id="image"><img alt="image" loading="lazy" src="/blogs/images/RxRzbjNHuooidzx93ZAcftCVnrf.png"><a hidden class="anchor" aria-hidden="true" href="#image">#</a></h2>
<h2 id="cls-token">CLS token<a hidden class="anchor" aria-hidden="true" href="#cls-token">#</a></h2>
<p>Reference:</p>
<p><a href="https://arxiv.org/pdf/1810.04805">https://arxiv.org/pdf/1810.04805</a></p>
<p><a href="https://h2o.ai/wiki/classify-token/">https://h2o.ai/wiki/classify-token/</a></p>
<h3 id="basic-concept">basic concept<a hidden class="anchor" aria-hidden="true" href="#basic-concept">#</a></h3>
<p>Classify token ([CLS]) is a special token used in NLP and ML models, particularly those based on the Transformer architecture. It is a token that represents the entire input sequence or sentence and is placed at the beginning of the input.CLS = Classification Token，是BERT等Transformer模型中的一个特殊标记，专门用于获取整个序列的聚合表示。</p>
<h3 id="how-it-works">how it works<a hidden class="anchor" aria-hidden="true" href="#how-it-works">#</a></h3>
<p>Classify token ([CLS]) serves as an input representation for the classification tasks in NLP and ML. It encapsulates the information from the entire input sequence and carries it through the model&rsquo;s layers for further processing. The model then uses this representation to make predictions or classify the input into predefined categories.</p>
<p>Classify token ([CLS]) plays a crucial role in NLP and ML tasks as it enables the model to perform classification on textual data. By incorporating the entire input sequence into a single representation, the model can capture important context and semantic information that aids in accurate classification. It helps the model understand the relationship between different words and their impact on the overall meaning of the text.</p>
<h3 id="use-cases">Use Cases<a hidden class="anchor" aria-hidden="true" href="#use-cases">#</a></h3>
<ul>
<li>
<p>Sentiment analysis: Determining the sentiment (positive, negative, or neutral) of a given text.</p>
</li>
<li>
<p>Text categorization: Classifying documents or articles into predefined categories.</p>
</li>
<li>
<p>Intent recognition: Identifying the intent or purpose behind a user&rsquo;s input in conversational AI systems.</p>
</li>
<li>
<p>Named entity recognition: Identifying and classifying named entities such as names, organizations, locations, etc., in text.</p>
</li>
</ul>
<h3 id="与普通token的区别">与普通token的区别<a hidden class="anchor" aria-hidden="true" href="#与普通token的区别">#</a></h3>
<p>以：The cat is running 为例</p>
<h4 id="cls-token的特殊身份">CLS Token的特殊身份<a hidden class="anchor" aria-hidden="true" href="#cls-token的特殊身份">#</a></h4>
<p>想象一个会议室里的讨论场景：</p>
<p>普通token（如&quot;cat&quot;, &ldquo;running&rdquo;） = 会议中的普通与会者</p>
<p>CLS token = 会议的主持人/记录员</p>
<h4 id="cls-token与普通token的根本区别">CLS Token与普通Token的根本区别<a hidden class="anchor" aria-hidden="true" href="#cls-token与普通token的根本区别">#</a></h4>
<h5 id="位置特殊性">位置特殊性<a hidden class="anchor" aria-hidden="true" href="#位置特殊性">#</a></h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>普通Token: 在句子中有具体的语义位置
</span></span><span style="display:flex;"><span>输入: &#34;The cat is running&#34;
</span></span><span style="display:flex;"><span>- &#34;The&#34; 在位置1，表示限定词
</span></span><span style="display:flex;"><span>- &#34;cat&#34; 在位置2，表示主语  
</span></span><span style="display:flex;"><span>- &#34;is&#34; 在位置3，表示谓语
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CLS Token: 永远在位置0，不表示任何具体语义
</span></span><span style="display:flex;"><span>输入: &#34;[CLS] The cat is running&#34;
</span></span><span style="display:flex;"><span>- &#34;[CLS]&#34; 在位置0，是个&#34;空容器&#34;，等待装入信息
</span></span></code></pre></div><h5 id="初始状态差异">初始状态差异<a hidden class="anchor" aria-hidden="true" href="#初始状态差异">#</a></h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>普通Token的初始状态:
</span></span><span style="display:flex;"><span>- &#34;cat&#34; 的embedding包含关于&#34;猫&#34;的语义信息
</span></span><span style="display:flex;"><span>- &#34;running&#34; 的embedding包含关于&#34;跑步&#34;的动作信息
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CLS Token的初始状态:
</span></span><span style="display:flex;"><span>- 只是一个随机初始化的向量
</span></span><span style="display:flex;"><span>- 不包含任何预定的语义信息
</span></span><span style="display:flex;"><span>- 像一张白纸，等待被写入内容
</span></span></code></pre></div><h4 id="注意力机制中的不同角色">注意力机制中的不同角色<a hidden class="anchor" aria-hidden="true" href="#注意力机制中的不同角色">#</a></h4>
<h5 id="第一层的注意力模式">第一层的注意力模式<a hidden class="anchor" aria-hidden="true" href="#第一层的注意力模式">#</a></h5>
<p>普通token &ldquo;cat&rdquo; 的注意力:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>&#34;cat&#34; 作为query时关注:
</span></span><span style="display:flex;"><span>- &#34;The&#34; (30%) - 了解这是特指的猫
</span></span><span style="display:flex;"><span>- &#34;cat&#34; (40%) - 保持自身信息  
</span></span><span style="display:flex;"><span>- &#34;is&#34; (20%) - 理解动作关系
</span></span><span style="display:flex;"><span>- &#34;running&#34; (10%) - 知道在做什么
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>目的: 丰富自己的语义理解
</span></span></code></pre></div><p>CLS token 的注意力:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>&#34;[CLS]&#34; 作为query时关注:
</span></span><span style="display:flex;"><span>- &#34;The&#34; (20%) - 收集限定信息
</span></span><span style="display:flex;"><span>- &#34;cat&#34; (30%) - 收集主语信息
</span></span><span style="display:flex;"><span>- &#34;is&#34; (20%) - 收集谓语信息  
</span></span><span style="display:flex;"><span>- &#34;running&#34; (30%) - 收集动作信息
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>目的: 平等地收集所有信息，不偏向任何特定词汇
</span></span></code></pre></div><h5 id="深层的注意力演进">深层的注意力演进<a hidden class="anchor" aria-hidden="true" href="#深层的注意力演进">#</a></h5>
<p>到第6层时:</p>
<p>普通token &ldquo;cat&rdquo;:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>现在的&#34;cat&#34;已经知道:
</span></span><span style="display:flex;"><span>- 自己是主语
</span></span><span style="display:flex;"><span>- 正在执行&#34;running&#34;动作
</span></span><span style="display:flex;"><span>- 在一个完整的句子中
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>注意力更加精准:
</span></span><span style="display:flex;"><span>- 主要关注与自己语法相关的词 (60%)
</span></span><span style="display:flex;"><span>- 适度关注其他内容 (40%)
</span></span></code></pre></div><p>CLS token:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>现在的&#34;[CLS]&#34;已经理解:
</span></span><span style="display:flex;"><span>- 整个句子的语法结构
</span></span><span style="display:flex;"><span>- 主要的语义关系
</span></span><span style="display:flex;"><span>- 句子的整体含义
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>注意力变得有选择性:
</span></span><span style="display:flex;"><span>- 重点关注核心内容词 &#34;cat&#34;(40%) + &#34;running&#34;(40%)  
</span></span><span style="display:flex;"><span>- 较少关注功能词 &#34;The&#34;(10%) + &#34;is&#34;(10%)
</span></span></code></pre></div><h4 id="信息聚合过程的直观对比">信息聚合过程的直观对比<a hidden class="anchor" aria-hidden="true" href="#信息聚合过程的直观对比">#</a></h4>
<h5 id="信息流向的差异">信息流向的差异<a hidden class="anchor" aria-hidden="true" href="#信息流向的差异">#</a></h5>
<p>普通token的信息更新:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>第1层: &#34;cat&#34; = 原始&#34;cat&#34;语义 + 少量上下文
</span></span><span style="display:flex;"><span>第6层: &#34;cat&#34; = 丰富的&#34;cat&#34;语义 + 大量上下文
</span></span><span style="display:flex;"><span>第12层: &#34;cat&#34; = 完整的上下文化&#34;cat&#34;表示
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>特点: 始终以&#34;cat&#34;的语义为核心，向外扩展
</span></span></code></pre></div><p>CLS token的信息更新:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>第1层: &#34;[CLS]&#34; = 空白 + 一点点各种信息
</span></span><span style="display:flex;"><span>第6层: &#34;[CLS]&#34; = 句子结构 + 主要语义关系  
</span></span><span style="display:flex;"><span>第12层: &#34;[CLS]&#34; = 完整的句子级表示
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>特点: 从空白开始，逐步装入整个句子的精华
</span></span></code></pre></div><h4 id="为什么cls-token能代表整个句子">为什么CLS Token能代表整个句子<a hidden class="anchor" aria-hidden="true" href="#为什么cls-token能代表整个句子">#</a></h4>
<h5 id="信息无损聚合的原理">信息无损聚合的原理<a hidden class="anchor" aria-hidden="true" href="#信息无损聚合的原理">#</a></h5>
<p>普通token的局限:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>每个普通token都有&#34;自我中心&#34;的倾向：
</span></span><span style="display:flex;"><span>- &#34;dog&#34; 主要关心与狗相关的信息
</span></span><span style="display:flex;"><span>- &#34;playing&#34; 主要关心动作相关的信息  
</span></span><span style="display:flex;"><span>- &#34;garden&#34; 主要关心地点相关的信息
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>如果让&#34;dog&#34;代表整个句子 → 会偏向动物信息
</span></span><span style="display:flex;"><span>如果让&#34;playing&#34;代表整个句子 → 会偏向动作信息
</span></span></code></pre></div><p>CLS token的优势:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>CLS token没有预设的语义偏好：
</span></span><span style="display:flex;"><span>- 不会偏向任何特定类型的信息
</span></span><span style="display:flex;"><span>- 可以平等地聚合所有类型的信息
</span></span><span style="display:flex;"><span>- 专门训练来承担&#34;全局总结&#34;的职责
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>就像一个专业的会议记录员，不会因为个人喜好
</span></span><span style="display:flex;"><span>而偏重记录某些内容，而是客观全面地记录
</span></span></code></pre></div><h5 id="梯度更新的特殊性">梯度更新的特殊性<a hidden class="anchor" aria-hidden="true" href="#梯度更新的特殊性">#</a></h5>
<p>普通token的更新目标:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>&#34;dog&#34; 的梯度目标：
</span></span><span style="display:flex;"><span>- 更好地表示&#34;狗&#34;这个概念
</span></span><span style="display:flex;"><span>- 更好地理解自己在句子中的作用
</span></span><span style="display:flex;"><span>- 保持与&#34;狗&#34;相关的语义特征
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>但这些都有&#34;自我中心&#34;的倾向
</span></span></code></pre></div><p>CLS token的更新目标:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>&#34;[CLS]&#34; 的梯度目标：
</span></span><span style="display:flex;"><span>- 更好地预测句子的整体标签（如情感、类别）
</span></span><span style="display:flex;"><span>- 更好地表示句子的整体语义
</span></span><span style="display:flex;"><span>- 学会如何从各个token提取最重要的信息
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>没有&#34;自我中心&#34;，完全为了整体效果而优化
</span></span></code></pre></div><hr>
<h2 id="bert">BERT<a hidden class="anchor" aria-hidden="true" href="#bert">#</a></h2>
<p>Reference:</p>
<p><a href="https://zhuanlan.zhihu.com/p/360343071">https://zhuanlan.zhihu.com/p/360343071</a></p>
<p><a href="http://arxiv.org/pdf/1810.04805">http://arxiv.org/pdf/1810.04805</a></p>
<p>Transformer (2017)</p>
<pre><code>├── Text Domain

│   └── LLM (GPT, BERT, T5...)

│

├── Vision Domain    │   └── ViT (2020) → Vision Transformers

│

├── Generation Domain

│   └── DiT (2022) → Diffusion + Transformer

│

└── Multimodal Domain

    ├── VLM → Vision + Language

    └── VLA → Vision + Language + Action
</code></pre>
<h3 id="masked-language-model-mlm">(Masked Language Model, MLM)<a hidden class="anchor" aria-hidden="true" href="#masked-language-model-mlm">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 核心思想：随机掩盖输入中的部分token，预测被掩盖的内容</span>
</span></span><span style="display:flex;"><span>原始句子: <span style="color:#e6db74">&#34;The cat sat on the mat&#34;</span>
</span></span><span style="display:flex;"><span>掩码处理: <span style="color:#e6db74">&#34;The [MASK] sat on the [MASK]&#34;</span>
</span></span><span style="display:flex;"><span>预测目标: 预测第2个位置是<span style="color:#e6db74">&#34;cat&#34;</span><span style="color:#960050;background-color:#1e0010">，</span>第6个位置是<span style="color:#e6db74">&#34;mat&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 具体实现</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_masked_lm_predictions</span>(tokens, masked_lm_prob<span style="color:#f92672">=</span><span style="color:#ae81ff">0.15</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    masked_lm_prob: 掩盖15%的token
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    output_tokens <span style="color:#f92672">=</span> list(tokens)
</span></span><span style="display:flex;"><span>    masked_lm_positions <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    masked_lm_labels <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, token <span style="color:#f92672">in</span> enumerate(tokens):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> random<span style="color:#f92672">.</span>random() <span style="color:#f92672">&lt;</span> masked_lm_prob:
</span></span><span style="display:flex;"><span>            masked_lm_positions<span style="color:#f92672">.</span>append(i)
</span></span><span style="display:flex;"><span>            masked_lm_labels<span style="color:#f92672">.</span>append(token)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># BERT的巧妙设计：</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> random<span style="color:#f92672">.</span>random() <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.8</span>:
</span></span><span style="display:flex;"><span>                output_tokens[i] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;[MASK]&#34;</span>     <span style="color:#75715e"># 80%: 替换为[MASK]</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> random<span style="color:#f92672">.</span>random() <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.5</span>:
</span></span><span style="display:flex;"><span>                output_tokens[i] <span style="color:#f92672">=</span> random_token  <span style="color:#75715e"># 10%: 替换为随机token  </span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># else: 保持原token不变              # 10%: 保持不变</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> output_tokens, masked_lm_positions, masked_lm_labels
</span></span></code></pre></div><p>为什么这样设计？</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 问题：如果总是用[MASK]替换，微调时会遇到分布偏移</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 训练时: &#34;The [MASK] is running&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 微调时: &#34;The dog is running&#34;  # 没有[MASK] token</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 解决方案：10%保持不变 + 10%随机替换</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 让模型学会在没有明确掩码信号时也能理解上下文</span>
</span></span></code></pre></div><h3 id="next-sentence-prediction-nsp">(Next Sentence Prediction, NSP)<a hidden class="anchor" aria-hidden="true" href="#next-sentence-prediction-nsp">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 目标：理解句子间的关系</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_nsp_data</span>(documents):
</span></span><span style="display:flex;"><span>    examples <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> doc <span style="color:#f92672">in</span> documents:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(doc) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 50%的正样本：连续的两个句子</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> random<span style="color:#f92672">.</span>random() <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0.5</span>:
</span></span><span style="display:flex;"><span>                sentence_a <span style="color:#f92672">=</span> doc[i]
</span></span><span style="display:flex;"><span>                sentence_b <span style="color:#f92672">=</span> doc[i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>                label <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>  <span style="color:#75715e"># IsNext</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># 50%的负样本：来自不同文档的句子</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                sentence_a <span style="color:#f92672">=</span> doc[i]
</span></span><span style="display:flex;"><span>                sentence_b <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>choice(random<span style="color:#f92672">.</span>choice(documents))
</span></span><span style="display:flex;"><span>                label <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>  <span style="color:#75715e"># NotNext</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            examples<span style="color:#f92672">.</span>append((sentence_a, sentence_b, label))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> examples
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 输入格式</span>
</span></span><span style="display:flex;"><span>input_format <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;[CLS] sentence_A [SEP] sentence_B [SEP]&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># CLS token的输出用于NSP分类</span>
</span></span></code></pre></div><h3 id="pre-trained-objective-function">Pre-trained Objective Function<a hidden class="anchor" aria-hidden="true" href="#pre-trained-objective-function">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 联合训练两个任务</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bert_pretraining_loss</span>(model_output, masked_positions, masked_labels, nsp_labels):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># MLM损失：只计算被掩盖位置的损失</span>
</span></span><span style="display:flex;"><span>    mlm_logits <span style="color:#f92672">=</span> model_output<span style="color:#f92672">.</span>prediction_logits[masked_positions]
</span></span><span style="display:flex;"><span>    mlm_loss <span style="color:#f92672">=</span> cross_entropy(mlm_logits, masked_labels)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># NSP损失：基于CLS token的输出</span>
</span></span><span style="display:flex;"><span>    nsp_logits <span style="color:#f92672">=</span> model_output<span style="color:#f92672">.</span>seq_relationship_logits
</span></span><span style="display:flex;"><span>    nsp_loss <span style="color:#f92672">=</span> cross_entropy(nsp_logits, nsp_labels)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 总损失</span>
</span></span><span style="display:flex;"><span>    total_loss <span style="color:#f92672">=</span> mlm_loss <span style="color:#f92672">+</span> nsp_loss
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> total_loss
</span></span></code></pre></div><h3 id="dual-direction-encoding-implementation">Dual-direction encoding implementation<a hidden class="anchor" aria-hidden="true" href="#dual-direction-encoding-implementation">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 与单向模型的对比</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># GPT (单向): 只能看到左边的context</span>
</span></span><span style="display:flex;"><span>attention_mask <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>],  <span style="color:#75715e"># token1只能看到自己</span>
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>],  <span style="color:#75715e"># token2能看到token1和自己  </span>
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>],  <span style="color:#75715e"># token3能看到前面所有</span>
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>]   <span style="color:#75715e"># token4能看到前面所有</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># BERT (双向): 可以看到所有位置的context</span>
</span></span><span style="display:flex;"><span>attention_mask <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>],  <span style="color:#75715e"># 每个token都能看到所有其他token</span>
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>],
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], 
</span></span><span style="display:flex;"><span>    [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><h3 id="encoder-vs-decoder">Encoder vs Decoder<a hidden class="anchor" aria-hidden="true" href="#encoder-vs-decoder">#</a></h3>
<ol>
<li>
<p>信息约束：Encoder无因果约束，Decoder有严格因果约束</p>
</li>
<li>
<p>优化目标：Encoder优化理解质量，Decoder优化生成概率</p>
</li>
<li>
<p>计算模式：Encoder并行处理，Decoder顺序处理</p>
</li>
<li>
<p>设计哲学：Encoder以理解为中心，Decoder以生成为中心</p>
</li>
</ol>
<p>非mask注意力和mask注意力机制</p>
<hr>
<h2 id="vlm">VLM<a hidden class="anchor" aria-hidden="true" href="#vlm">#</a></h2>
<p>Reference：</p>
<p><a href="https://zhuanlan.zhihu.com/p/701039113">https://zhuanlan.zhihu.com/p/701039113</a></p>
<hr>
<h2 id="pope">POPE<a hidden class="anchor" aria-hidden="true" href="#pope">#</a></h2>
<p>Reference:</p>
<p><a href="https://zhuanlan.zhihu.com/p/699623105">https://zhuanlan.zhihu.com/p/699623105</a></p>
<p><a href="https://arxiv.org/pdf/2305.10355">https://arxiv.org/pdf/2305.10355</a></p>
<p><img alt="image" loading="lazy" src="/blogs/images/XUZubPm4KoCUj9xRvbZcvnBfnqe.png"></p>
<p>a more suitable method for the stable, fair and flexible object hallucination evaluation of LVLMs, namely pollingbased object probing evaluation (POPE). Specifically, POPE formulates the evaluation of object hallucination as a binary classification task that prompts LVLMs to output “Yes” or “No”, e.g., “Is there a chair in the image?”. In this way, by sampling objects that LVLMs are prone to hallucinate, we can construct a set of hard questions to poll LVLMs. As standard answers to these questions are just “Yes” or “No”, we can easily identify them without complex parsing rules, and avoid the influence of instruction designs and caption length, thus guaranteeing stability, fairness and flexibility</p>
<h2 id="kv-cache">KV cache<a hidden class="anchor" aria-hidden="true" href="#kv-cache">#</a></h2>
<h2 id="ggml">GGML<a hidden class="anchor" aria-hidden="true" href="#ggml">#</a></h2>
<p>Reference:</p>
<p><a href="https://huggingface.co/blog/introduction-to-ggml">https://huggingface.co/blog/introduction-to-ggml</a></p>
<p>ggml 默认计算方式：调用 <code>ggml_mul_mat()</code></p>
<p>在 <code>llama.cpp</code> 中的前向传播过程中，比如线性层（FullyConnected Layer）会构造：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>ggml_mul_mat(A, B)
</span></span></code></pre></div><p>这构建了一个“图节点”，之后由：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>llama_graph_compute(graph)
</span></span></code></pre></div><h2 id="gumbel-softmax">Gumbel-Softmax<a hidden class="anchor" aria-hidden="true" href="#gumbel-softmax">#</a></h2>
<hr>
<h2 id="low-rank-attention">Low-rank Attention<a hidden class="anchor" aria-hidden="true" href="#low-rank-attention">#</a></h2>
<p>Nadaraya–Watson Regression（纳达拉亚–沃森回归）是一种非常经典的非参数回归方法，本质上是加权平均法，用于拟合数据的平滑曲线，尤其常见于**核回归（kernel regression）**和一些深度学习中的可解释性模块。</p>
<h2 id="image-1"><img alt="image" loading="lazy" src="/blogs/images/DKvobAtYpoNmvfxOtAFc3xW7nif.png"><a hidden class="anchor" aria-hidden="true" href="#image-1">#</a></h2>
<h3 id="maths-explanation">Maths explanation<a hidden class="anchor" aria-hidden="true" href="#maths-explanation">#</a></h3>
<p>假设我们有一组训练样本 (xi,yi)(x_i, y_i)，现在想预测一个新点 xx 的函数值 y(x)y(x)，Nadaraya–Watson 回归形式为：</p>
<p>$$
y^(x)=∑i=1nK(x,xi)⋅yi∑i=1nK(x,xi)\hat{y}(x) = \frac{\sum_{i=1}^n K(x, x_i) \cdot y_i}{\sum_{i=1}^n K(x, x_i)}
$$</p>
<p>其中：</p>
<ul>
<li>
<p>K(x,xi)K(x, x_i) 是一个核函数（kernel function），常用高斯核：</p>
</li>
<li>
<p>K(x,xi)=exp⁡(−(x−xi)22h2)K(x, x_i) = \exp\left(-\frac{(x - x_i)^2}{2h^2}\right)</p>
</li>
<li>
<p>hh：称为带宽参数（bandwidth），控制“邻近范围”大小。</p>
</li>
</ul>
<hr>
<p><strong>Nadaraya–Watson 回归 = 用邻近样本的加权平均来平滑预测结果，是核方法的基础形式，类似软注意力机制。</strong></p>
<hr>
<h2 id="covers-theme">Cover&rsquo;s theme<a hidden class="anchor" aria-hidden="true" href="#covers-theme">#</a></h2>
<p><a href="https://kexue.fm/archives/7546">https://kexue.fm/archives/7546</a></p>
<hr>
<h2 id="gpu-storage">GPU storage<a hidden class="anchor" aria-hidden="true" href="#gpu-storage">#</a></h2>
<p><a href="https://zhuanlan.zhihu.com/p/29264672961">https://zhuanlan.zhihu.com/p/29264672961</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/462191421">https://zhuanlan.zhihu.com/p/462191421</a></p>
<p><a href="https://github.com/CalvinXKY/BasicCUDA/tree/master/memory_opt">https://github.com/CalvinXKY/BasicCUDA/tree/master/memory_opt</a></p>
<hr>
<h2 id="pip-install">pip install<a hidden class="anchor" aria-hidden="true" href="#pip-install">#</a></h2>
<p>在使用 <code>pip install</code> 命令时，“后缀 option（-&hellip;）”实际上是指 命令行选项（command-line options），它们以 <code>-</code> 或 <code>--</code> 开头，用于控制 <code>pip install</code> 的行为。这些选项可以改变安装方式、指定源、启用特定功能等。</p>
<h3 id="options">Options<a hidden class="anchor" aria-hidden="true" href="#options">#</a></h3>
<table>
  <thead>
      <tr>
          <th>选项</th>
          <th>含义</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>-r, --requirement &lt;file&gt;</code></td>
          <td>从文件中读取要安装的包列表（通常是 <code>requirements.txt</code>）<br>例：<code>pip install -r requirements.txt</code></td>
      </tr>
      <tr>
          <td><code>-e, --editable &lt;path/url&gt;</code></td>
          <td>以“可编辑模式”安装包（开发模式），修改源码立即生效<br>例：<code>pip install -e .</code></td>
      </tr>
      <tr>
          <td><code>-i, --index-url &lt;url&gt;</code></td>
          <td>指定包的索引源（PyPI 镜像地址）<br>例：<code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy</code></td>
      </tr>
      <tr>
          <td><code>--extra-index-url &lt;url&gt;</code></td>
          <td>添加额外的包索引源</td>
      </tr>
      <tr>
          <td><code>--no-index</code></td>
          <td>不使用任何索引，只从本地目录或 <code>--find-links</code> 安装</td>
      </tr>
      <tr>
          <td><code>-f, --find-links &lt;url/path&gt;</code></td>
          <td>指定查找包的额外路径（本地或网络）<br>例：<code>pip install -f ./packages/ mypackage</code></td>
      </tr>
      <tr>
          <td><code>--no-deps, --no-dependencies</code></td>
          <td>安装包但不安装其依赖项<br>例：<code>pip install --no-deps requests</code></td>
      </tr>
      <tr>
          <td><code>--force-reinstall</code></td>
          <td>重新安装包，即使它已经存在</td>
      </tr>
      <tr>
          <td><code>--upgrade, -U</code></td>
          <td>升级包到最新版本<br>例：<code>pip install --upgrade package_name</code></td>
      </tr>
      <tr>
          <td><code>-t, --target &lt;dir&gt;</code></td>
          <td>将包安装到指定目录，而不是当前环境</td>
      </tr>
      <tr>
          <td><code>-c, --constraint &lt;file&gt;</code></td>
          <td>指定版本约束文件，限制版本升级范围</td>
      </tr>
      <tr>
          <td><code>--user</code></td>
          <td>安装到用户目录（避免使用 <code>sudo</code>）<br>例：<code>pip install --user package_name</code></td>
      </tr>
      <tr>
          <td><code>--proxy &lt;proxy&gt;</code></td>
          <td>使用代理访问网络</td>
      </tr>
      <tr>
          <td><code>--timeout &lt;sec&gt;</code></td>
          <td>设置连接超时时间</td>
      </tr>
      <tr>
          <td><code>-v, --verbose</code></td>
          <td>增加输出详细程度（可多次使用 <code>-vvv</code>）</td>
      </tr>
      <tr>
          <td><code>-q, --quiet</code></td>
          <td>减少输出信息</td>
      </tr>
      <tr>
          <td><code>--pre</code></td>
          <td>允许安装预发布版本（如 alpha、beta、rc）<br>例：<code>pip install --pre package_name</code></td>
      </tr>
      <tr>
          <td><code>--no-cache-dir</code></td>
          <td>禁用缓存，强制重新下载包</td>
      </tr>
  </tbody>
</table>
<h3 id="further-use">further use<a hidden class="anchor" aria-hidden="true" href="#further-use">#</a></h3>
<h2 id="referencehttpszhuanlanzhihucomp673336277">Reference：https://zhuanlan.zhihu.com/p/673336277<a hidden class="anchor" aria-hidden="true" href="#referencehttpszhuanlanzhihucomp673336277">#</a></h2>
<h2 id="normalization">Normalization<a hidden class="anchor" aria-hidden="true" href="#normalization">#</a></h2>
<p>Reference: <a href="https://www.cnblogs.com/wuliytTaotao/p/10837533.html">https://www.cnblogs.com/wuliytTaotao/p/10837533.html</a></p>
<h2 id="reference">Reference: <a href="https://0809zheng.github.io/2020/03/03/regularization.html">https://0809zheng.github.io/2020/03/03/regularization.html</a><a hidden class="anchor" aria-hidden="true" href="#reference">#</a></h2>
<h2 id="mle">MLE<a hidden class="anchor" aria-hidden="true" href="#mle">#</a></h2>
<h2 id="最大似然估计">最大似然估计<a hidden class="anchor" aria-hidden="true" href="#最大似然估计">#</a></h2>
<h2 id="alignment-of-pytorch-cuda-python">Alignment of Pytorch, CUDA, Python<a hidden class="anchor" aria-hidden="true" href="#alignment-of-pytorch-cuda-python">#</a></h2>
<h3 id="supported-newest-cuda-version">Supported newest CUDA version<a hidden class="anchor" aria-hidden="true" href="#supported-newest-cuda-version">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>nvidia-smi
</span></span><span style="display:flex;"><span>python -c &#34;import torch; print(torch.__version__); print(torch.cuda.is_available())&#34;
</span></span></code></pre></div><h3 id="torch-cuda-alignment"><a href="https://pytorch.org/get-started/previous-versions/">torch cuda</a> alignment<a hidden class="anchor" aria-hidden="true" href="#torch-cuda-alignment">#</a></h3>
<h3 id="flash-attn-alignment">flash-attn alignment<a hidden class="anchor" aria-hidden="true" href="#flash-attn-alignment">#</a></h3>
<p>首先检查你的cuda版本，通过nvcc -V查看环境是否含有cuda以及版本是否在11.6及以上，如果没有需要自己安装，下载地址在这里：<a href="https://link.zhihu.com/?target=https%3A//developer.nvidia.com/cuda-toolkit-archive">cuda-toolkit</a></p>
<p><a href="https://github.com/Dao-AILab/flash-attention/releases">https://github.com/Dao-AILab/flash-attention/releases</a>在这个里面找到对应的版本下载即可</p>
<h2 id="safetensor-config-download-to-local">Safetensor, Config, Download to local<a hidden class="anchor" aria-hidden="true" href="#safetensor-config-download-to-local">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cd <span style="color:#f92672">../</span>etc
</span></span><span style="display:flex;"><span>source network_turbo
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>pip install <span style="color:#f92672">-</span>U huggingface_hub
</span></span><span style="display:flex;"><span>apt install aria2c
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sudo apt install aria2c</span>
</span></span><span style="display:flex;"><span>wget https:<span style="color:#f92672">//</span>hf<span style="color:#f92672">-</span>mirror<span style="color:#f92672">.</span>com<span style="color:#f92672">/</span>hfd<span style="color:#f92672">/</span>hfd<span style="color:#f92672">.</span>sh
</span></span><span style="display:flex;"><span>chmod a<span style="color:#f92672">+</span>x hfd<span style="color:#f92672">.</span>sh
</span></span><span style="display:flex;"><span>export HF_ENDPOINT<span style="color:#f92672">=</span>https:<span style="color:#f92672">//</span>hf<span style="color:#f92672">-</span>mirror<span style="color:#f92672">.</span>com
</span></span><span style="display:flex;"><span><span style="color:#f92672">./</span>hfd<span style="color:#f92672">.</span>sh model_name <span style="color:#f92672">--</span>tool aria2c <span style="color:#f92672">-</span>x <span style="color:#ae81ff">10</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scp <span style="color:#f92672">-</span>P xxxxx <span style="color:#f92672">-</span>r user<span style="color:#a6e22e">@xxxx</span>:<span style="color:#f92672">/</span>path<span style="color:#f92672">/</span>to<span style="color:#f92672">/</span>your<span style="color:#f92672">/</span>file <span style="color:#f92672">./</span>path<span style="color:#f92672">/</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 不推荐传大文件，小的可以，从本地传到服务器远端</span>
</span></span><span style="display:flex;"><span>scp <span style="color:#f92672">-</span>v <span style="color:#75715e">#detail info</span>
</span></span><span style="display:flex;"><span>scp <span style="color:#f92672">-</span>q <span style="color:#75715e"># quiet</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>wget <span style="color:#75715e"># Web get</span>
</span></span><span style="display:flex;"><span>aria2c <span style="color:#75715e"># 多线程</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 优先用后者，get address的时候注意不要cp了web的地址，而要raw file的地址</span>
</span></span><span style="display:flex;"><span>aria2c https:<span style="color:#f92672">//</span>raw<span style="color:#f92672">.</span>githubusercontent<span style="color:#f92672">.</span>com<span style="color:#f92672">/</span>AoiDragon<span style="color:#f92672">/</span>POPE<span style="color:#f92672">/</span>e3e39262c85a6a83f26cf5094022a782cb0df58d<span style="color:#f92672">/</span>output<span style="color:#f92672">/</span>coco<span style="color:#f92672">/</span>coco_pope_random<span style="color:#f92672">.</span>json
</span></span><span style="display:flex;"><span><span style="color:#75715e"># detailed </span>
</span></span><span style="display:flex;"><span>https:<span style="color:#f92672">//</span>www<span style="color:#f92672">.</span>cnblogs<span style="color:#f92672">.</span>com<span style="color:#f92672">/</span>TangQF<span style="color:#f92672">/</span>articles<span style="color:#f92672">/</span><span style="color:#ae81ff">18714419</span>
</span></span></code></pre></div><h2 id="dataset">Dataset<a hidden class="anchor" aria-hidden="true" href="#dataset">#</a></h2>
<p><a href="https://huggingface.co/datasets/lmms-lab/MME">MME</a> / <a href="https://huggingface.co/datasets/lmms-lab/POPE">POPE</a> / <a href="https://huggingface.co/datasets/lmms-lab/textvqa">textvqa</a> &hellip;</p>
<p><a href="https://huggingface.co/collections/lmms-lab/lmms-eval-661d51f70a9d678b6f43f272">https://huggingface.co/collections/lmms-lab/lmms-eval-661d51f70a9d678b6f43f272</a></p>
<p>在这里找多模态模型的所有数据集去下载，别在github里下通常不是放真正数据集的仓库</p>
<h2 id="vim-use">Vim Use<a hidden class="anchor" aria-hidden="true" href="#vim-use">#</a></h2>
<p><strong>全选（高亮显示</strong>）：按esc后，然后ggvG或者ggVG</p>
<p>**全部复制：**按esc后，然后ggyG</p>
<p>**全部删除：**按esc后，然后dG</p>
<p>解析：</p>
<p><strong>gg：<strong>是让光标移到首行，在</strong>vim</strong>才有效，vi中无效</p>
<p><strong>v ：</strong> 是进入Visual(可视）模式</p>
<p>**G ：**光标移到最后一行</p>
<p><strong>选</strong>中内容以后就可以其他的操作了，比如：
<strong>d</strong>  删除<strong>选</strong>中内容
<strong>y</strong>  复制<strong>选</strong>中内容到0号寄存器
<strong>&quot;+y</strong>  复制<strong>选</strong>中内容到＋寄存器，也就是系统的剪贴板，供其他程序用</p>
<h2 id="cpmv-path">cp/mv PATH<a hidden class="anchor" aria-hidden="true" href="#cpmv-path">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span>cp 命令
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  # 情况1：复制目录内容
</span></span><span style="display:flex;"><span>  cp -r source_dir/ dest_dir/
</span></span><span style="display:flex;"><span>  # 结果：source_dir里的所有文件复制到dest_dir里
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  # 情况2：复制整个目录
</span></span><span style="display:flex;"><span>  cp -r source_dir dest_dir/
</span></span><span style="display:flex;"><span>  # 结果：在dest_dir里创建source_dir文件夹
</span></span><span style="display:flex;"><span>mv 命令
</span></span><span style="display:flex;"><span>移动到目录内
</span></span><span style="display:flex;"><span>  mv file.txt dir1/        # file.txt移动到dir1目录里
</span></span><span style="display:flex;"><span>  mv file.txt dir1/dir2/   # file.txt移动到dir1/dir2目录里
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>重命名
</span></span><span style="display:flex;"><span>  mv file.txt newname.txt  # 重命名文件
</span></span><span style="display:flex;"><span>  mv dir1 newdir          # 重命名目录
</span></span></code></pre></div><h2 id="ridge-regression----square-loss">Ridge regression  &amp;&amp;  Square loss<a hidden class="anchor" aria-hidden="true" href="#ridge-regression----square-loss">#</a></h2>
<ol>
<li>
<p>岭回归是：假设参数w有高斯先验（prior），从而改变MAP最大后验，在求解的时候约束参数分布</p>
</li>
<li>
<p><code>square loss</code>是：如果假设误差服从 <strong>高斯分布</strong>，那么用 <strong>最大似然估计</strong><code>**(MLE)**</code> 来推参数，就自然等价于最小化 <strong>平方损失</strong>。一般都会默认噪声是gaussian分布的，这样得到的普通最小二乘回归；但缺点也很明显就是平方损失对 outlier 太敏感。实际应用里，经常需要根据数据特点选择更合适的噪声模型，从而得到更鲁棒的损失函数。</p>
</li>
<li>
<p>似然更像是从数据推参数：概率是已知参数下看数据的可能性；似然是已知数据下看参数的可能性。</p>
</li>
</ol>
<p>似然：数据给参数的证据。</p>
<p>先验：数据之前你对参数的信念。</p>
<p>后验：结合两者，数据之后你对参数的新信念。</p>
<h2 id="for-circle">for circle<a hidden class="anchor" aria-hidden="true" href="#for-circle">#</a></h2>
<p>首先看当前循环头部和循环头部的差值，就是i+=？；</p>
<p>再看循环几次，就是i max（！）=n*？；</p>
<p>再看次要条件，可以考虑将？和！都缩小一半；然后循环内主索引扩一倍。</p>
<p>$$
d_{L2}(x,y) = \sqrt{\sum_{i=1}^{d}(x_i - y_i)^2}
$$</p>
<p>$$
d_{cosine}(x,y) = 1 - \frac{x \cdot y}{||x|| \cdot ||y||}
$$</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/blogs/posts/format/">
    <span class="title">« Prev</span>
    <br>
    <span>Format</span>
  </a>
  <a class="next" href="http://localhost:1313/blogs/posts/vlm-pruning--hw-and-alg-co-design/">
    <span class="title">Next »</span>
    <br>
    <span>VLM pruning : Hw and Alg co-design</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PRML-DL on x"
            href="https://x.com/intent/tweet/?text=PRML-DL&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PRML-DL on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f&amp;title=PRML-DL&amp;summary=PRML-DL&amp;source=http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PRML-DL on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f&title=PRML-DL">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PRML-DL on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PRML-DL on whatsapp"
            href="https://api.whatsapp.com/send?text=PRML-DL%20-%20http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PRML-DL on telegram"
            href="https://telegram.me/share/url?text=PRML-DL&amp;url=http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share PRML-DL on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=PRML-DL&u=http%3a%2f%2flocalhost%3a1313%2fblogs%2fposts%2fprml-dl%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/blogs/">LArielO&#39;s LAB</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
